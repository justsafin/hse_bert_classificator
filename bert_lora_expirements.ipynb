{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from ast import literal_eval\n",
    "from datasets import load_from_disk\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, TrainerCallback\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\"\n",
    "# Path to Huggingface pre-processed dataset\n",
    "\n",
    "experiment_path = Path(f\"exps/experiment_{int(time.time())}\")\n",
    "experiment_path.mkdir(parents=True, exist_ok=True)\n",
    "output_path=experiment_path\n",
    "# \"Path to store the fine-tuned model\",\n",
    "\n",
    "model_name=\"\"\n",
    "# \"Name of the pre-trained LLM to fine-tune\",\n",
    "\n",
    "max_length=\"\"\n",
    "# \"Maximum length of the input sequences\",\n",
    "\n",
    "set_pad_id=\"\" \n",
    "# \"Set the id for the padding token, needed by models such as Mistral-7B\",\n",
    "\n",
    "lr=1e-5\n",
    "# Learning rate for training\"\n",
    "\n",
    "train_batch_size=36\n",
    "# Train batch size\n",
    "\n",
    "eval_batch_size=36\n",
    "# Eval batch size\"\n",
    "\n",
    "num_epochs=5\n",
    "# Number of epochs\"\n",
    "\n",
    "weight_decay=0.1\n",
    "# Weight decay\"\n",
    "\n",
    "lora_rank=4,\n",
    "# help=\"Lora rank\"\n",
    "\n",
    "\n",
    "lora_alpha=0.0\n",
    "# Lora alpha\"\n",
    "\n",
    "lora_dropout=0.2\n",
    "# Lora dropout\"\n",
    "\n",
    "lora_bias=None\n",
    "# choices={\"lora_only\", \"none\", 'all'},\n",
    "# help=\"Layers to add learnable bias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.astype(np.int32) \n",
    "    \n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "    pred_labels_cpu = torch.sigmoid(logits_tensor).detach().cpu().numpy()\n",
    "    predictions = np.where(pred_labels_cpu<0.5, 0, 1).astype(np.int32) \n",
    "\n",
    "\n",
    "    print(f\"predictions = {predictions} {predictions.shape}\")\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=predictions)\n",
    "    f1 = f1_score(y_true=labels, y_pred=predictions, average=\"micro\")\n",
    "    f1_macro = f1_score(y_true=labels, y_pred=predictions, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_true=labels, y_pred=predictions, average=\"weighted\")\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1, \"f1_macro\": f1_macro, 'f1_weighted': f1_weighted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(TrainerCallback):\n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(df):\n",
    "    # Flatten the 'keys' column\n",
    "    all_labels = [label for sublist in df['RGNTI_L1'] for label in sublist]\n",
    "\n",
    "    # Get unique classes\n",
    "    unique_classes = np.unique(all_labels)\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=unique_classes,\n",
    "        y=all_labels\n",
    "    )\n",
    "\n",
    "    # Create a dictionary mapping from class to weight\n",
    "    class_weights_dict = dict(zip(unique_classes, class_weights))\n",
    "\n",
    "    print(\"Class weights:\", class_weights_dict)\n",
    "    return class_weights, class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_and_collator(teach_df,\n",
    "                             test_df,\n",
    "                             model_checkpoints,\n",
    "                             add_prefix_space=True,\n",
    "                             max_length=512,\n",
    "                             truncation=True,\n",
    "                             set_pad_id=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Load the preprocessed HF dataset with train, valid and test objects\n",
    "    \n",
    "    Paramters:\n",
    "    ---------\n",
    "    data_path: str \n",
    "        Path to the pre-processed HuggingFace dataset \n",
    "    model_checkpoints: \n",
    "        Name of the pre-trained model to use for tokenization\n",
    "    \"\"\"\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(teach_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "    data = DatasetDict({\"train\":train_dataset,\"test\":test_dataset})\n",
    "    \n",
    "    # data = Dataset.from_pandas(df)\n",
    "    # data = data.train_test_split(test_size=0.2, shuffle=False)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_checkpoints,\n",
    "        add_prefix_space=add_prefix_space\n",
    "    )\n",
    "\n",
    "    if set_pad_id:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    def _preprocesscing_function(examples):\n",
    "        return tokenizer(examples['data'], truncation=truncation, max_length=max_length)\n",
    "\n",
    "    col_to_delete = ['data', 'RGNTI_L1', 'RGNTI_L2']\n",
    "    tokenized_datasets = data.map(_preprocesscing_function, batched=False)\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns(col_to_delete)\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"onehot_level1\", \"label\")\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    padding_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    return tokenized_datasets, padding_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lora_model(model_checkpoints, id2label, label2id, num_labels=46, rank=4, alpha=16, lora_dropout=0.1, bias='none'):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_checkpoints,\n",
    "            problem_type=\"multi_label_classification\",\n",
    "            num_labels=num_labels,\n",
    "            # device_map=\"auto\",\n",
    "            offload_folder=\"offload\",\n",
    "            trust_remote_code=True,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id\n",
    "        )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS, r=rank, lora_alpha=alpha, lora_dropout=lora_dropout, bias=bias,\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    print(model.print_trainable_parameters())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def get_one_level_labels(df, field):\n",
    "    # new_field_title = field + \"_proc\"\n",
    "    df[field] = df[field].apply(literal_eval)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    sparce_labels = mlb.fit_transform(df[field])\n",
    "    level_classes = mlb.classes_\n",
    "    print(f\"Unique {field} classes: {len(level_classes)}\")\n",
    "\n",
    "    return level_classes, sparce_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique RGNTI_L1 classes: 46\n",
      "Class weights: {'00': 240.37649653434153, '06': 0.7880447693671101, '12': 20.25149970802145, '15': 2.8780111505933657, '19': 16.29270949004869, '20': 2.3456340349129636, '27': 1.7132505175983437, '28': 1.9728771572343957, '29': 0.44950886933897677, '30': 0.9502680337383732, '31': 0.3033557980954653, '34': 0.17008643040424104, '36': 3.0851894086438922, '37': 1.6454343512767426, '38': 0.5185548932583888, '39': 0.6788906823654196, '41': 3.3588453343194744, '44': 0.6615075284517037, '45': 1.7644657724329325, '47': 0.8376756697408871, '49': 1.6667649744618194, '50': 0.9887908823697129, '52': 0.5179395515994618, '53': 0.5805179468996383, '55': 0.3665733603162614, '58': 1842.8864734299516, '59': 1507.8162055335968, '60': 4.196856847386024, '61': 0.33185894597470067, '62': 3.4360841642572124, '64': 4.85253898796652, '65': 1.979469896272773, '66': 10.770115753811407, '67': 21.9391246836899, '68': 1.0558937013540595, '69': 30.432987634623057, '70': 2.6352046807863942, '73': 0.5803960618983646, '75': 18.347321085032704, '76': 0.834976754977324, '81': 0.6859946340007265, '82': 2.3281833605937066, '86': 101.13401378579003, '87': 0.4127199905658438, '89': 1.023762623348532, '90': 2.644026504203661}\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"C:\\\\PowerfullProject\\\\teach_slice_80_l2_drop_wasted_v2.csv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"C:\\\\PowerfullProject\\\\test_slice_20_l2_drop_wasted_v2.csv\", sep=\"\\t\")\n",
    "result = pd.concat([df_train, df_test])\n",
    "l1_classes, l1_labels = get_one_level_labels(result, 'RGNTI_L1')\n",
    "l1_labels = l1_labels.astype(float) \n",
    "result['onehot_level1'] = l1_labels.tolist()\n",
    "id2label = {idx:label for idx, label in enumerate(l1_classes)}\n",
    "label2id = {label:idx for idx, label in enumerate(l1_classes)}\n",
    "class_weights, class_weights_dict = compute_class_weights(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>RGNTI_L1</th>\n",
       "      <th>RGNTI_L2</th>\n",
       "      <th>onehot_level1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Распределение ртути в компонентах окружающей с...</td>\n",
       "      <td>[87, 38, 52]</td>\n",
       "      <td>['52.01', '38.63', '52.45', '87.23', '87.03']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Химический состав фракций обломочного материал...</td>\n",
       "      <td>[87, 38, 52]</td>\n",
       "      <td>['87.19', '87.53', '52.13', '87.23', '38.33']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>НАНОРАЗМЕРНЫЕ ЧАСТИЦЫ ПРИ ОСВОЕНИИ НЕДР: ОБРАЗ...</td>\n",
       "      <td>[61, 52, 87]</td>\n",
       "      <td>['61.53', '87.23', '52.45', '52.01']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Анализ условий восстановления растительности н...</td>\n",
       "      <td>[87, 38, 52]</td>\n",
       "      <td>['38.63', '38.33', '87.23', '52.01']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Обобщенная оценка влияния горного предприятия ...</td>\n",
       "      <td>[87, 38, 52]</td>\n",
       "      <td>['38.33', '87.23', '52.45', '52.01']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84448</th>\n",
       "      <td>Неравенства Харди в предельном случае на сфере...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>['27.25']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84449</th>\n",
       "      <td>Неравенство Пуанкаре и $p$-связность стратифиц...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>['27.25']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84450</th>\n",
       "      <td>Неулучшаемость теоремы Дирихле для многочленов...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>['27.15']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84451</th>\n",
       "      <td>Основные направления реализации программы импо...</td>\n",
       "      <td>[59]</td>\n",
       "      <td>['59.01']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84452</th>\n",
       "      <td>Конструкторское бюро УК ООО \"ТМС групп\": от эс...</td>\n",
       "      <td>[55]</td>\n",
       "      <td>['55.69']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599248 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data      RGNTI_L1  \\\n",
       "0      Распределение ртути в компонентах окружающей с...  [87, 38, 52]   \n",
       "1      Химический состав фракций обломочного материал...  [87, 38, 52]   \n",
       "2      НАНОРАЗМЕРНЫЕ ЧАСТИЦЫ ПРИ ОСВОЕНИИ НЕДР: ОБРАЗ...  [61, 52, 87]   \n",
       "3      Анализ условий восстановления растительности н...  [87, 38, 52]   \n",
       "4      Обобщенная оценка влияния горного предприятия ...  [87, 38, 52]   \n",
       "...                                                  ...           ...   \n",
       "84448  Неравенства Харди в предельном случае на сфере...          [27]   \n",
       "84449  Неравенство Пуанкаре и $p$-связность стратифиц...          [27]   \n",
       "84450  Неулучшаемость теоремы Дирихле для многочленов...          [27]   \n",
       "84451  Основные направления реализации программы импо...          [59]   \n",
       "84452  Конструкторское бюро УК ООО \"ТМС групп\": от эс...          [55]   \n",
       "\n",
       "                                            RGNTI_L2  \\\n",
       "0      ['52.01', '38.63', '52.45', '87.23', '87.03']   \n",
       "1      ['87.19', '87.53', '52.13', '87.23', '38.33']   \n",
       "2               ['61.53', '87.23', '52.45', '52.01']   \n",
       "3               ['38.63', '38.33', '87.23', '52.01']   \n",
       "4               ['38.33', '87.23', '52.45', '52.01']   \n",
       "...                                              ...   \n",
       "84448                                      ['27.25']   \n",
       "84449                                      ['27.25']   \n",
       "84450                                      ['27.15']   \n",
       "84451                                      ['59.01']   \n",
       "84452                                      ['55.69']   \n",
       "\n",
       "                                           onehot_level1  \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "...                                                  ...  \n",
       "84448  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "84449  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "84450  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "84451  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "84452  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[599248 rows x 4 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9606c89d306c4114a48a204abb57dee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/514795 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262401e5669d4507949a537359a0a224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_test = pd.read_csv(\"C:\\\\PowerfullProject\\\\test_slice_20_l2_drop_wasted_v2.csv\", sep=\"\\t\")\n",
    "embedding_model_name = \"miemBertProject/miem-scibert-linguistic\"\n",
    "dataset, collator =  get_dataset_and_collator(result[:514795],\n",
    "                                              result[514795:],\n",
    "                                              embedding_model_name,\n",
    "                                              max_length=256,\n",
    "                                              set_pad_id=False,\n",
    "                                              add_prefix_space=True,\n",
    "                                              truncation=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {'00': 240.37649653434153, '06': 0.7880447693671101, '12': 20.25149970802145, '15': 2.8780111505933657, '19': 16.29270949004869, '20': 2.3456340349129636, '27': 1.7132505175983437, '28': 1.9728771572343957, '29': 0.44950886933897677, '30': 0.9502680337383732, '31': 0.3033557980954653, '34': 0.17008643040424104, '36': 3.0851894086438922, '37': 1.6454343512767426, '38': 0.5185548932583888, '39': 0.6788906823654196, '41': 3.3588453343194744, '44': 0.6615075284517037, '45': 1.7644657724329325, '47': 0.8376756697408871, '49': 1.6667649744618194, '50': 0.9887908823697129, '52': 0.5179395515994618, '53': 0.5805179468996383, '55': 0.3665733603162614, '58': 1842.8864734299516, '59': 1507.8162055335968, '60': 4.196856847386024, '61': 0.33185894597470067, '62': 3.4360841642572124, '64': 4.85253898796652, '65': 1.979469896272773, '66': 10.770115753811407, '67': 21.9391246836899, '68': 1.0558937013540595, '69': 30.432987634623057, '70': 2.6352046807863942, '73': 0.5803960618983646, '75': 18.347321085032704, '76': 0.834976754977324, '81': 0.6859946340007265, '82': 2.3281833605937066, '86': 101.13401378579003, '87': 0.4127199905658438, '89': 1.023762623348532, '90': 2.644026504203661}\n",
      "[2.40376497e+02 7.88044769e-01 2.02514997e+01 2.87801115e+00\n",
      " 1.62927095e+01 2.34563403e+00 1.71325052e+00 1.97287716e+00\n",
      " 4.49508869e-01 9.50268034e-01 3.03355798e-01 1.70086430e-01\n",
      " 3.08518941e+00 1.64543435e+00 5.18554893e-01 6.78890682e-01\n",
      " 3.35884533e+00 6.61507528e-01 1.76446577e+00 8.37675670e-01\n",
      " 1.66676497e+00 9.88790882e-01 5.17939552e-01 5.80517947e-01\n",
      " 3.66573360e-01 1.84288647e+03 1.50781621e+03 4.19685685e+00\n",
      " 3.31858946e-01 3.43608416e+00 4.85253899e+00 1.97946990e+00\n",
      " 1.07701158e+01 2.19391247e+01 1.05589370e+00 3.04329876e+01\n",
      " 2.63520468e+00 5.80396062e-01 1.83473211e+01 8.34976755e-01\n",
      " 6.85994634e-01 2.32818336e+00 1.01134014e+02 4.12719991e-01\n",
      " 1.02376262e+00 2.64402650e+00]\n",
      "tensor([2.4038e+02, 7.8804e-01, 2.0251e+01, 2.8780e+00, 1.6293e+01, 2.3456e+00,\n",
      "        1.7133e+00, 1.9729e+00, 4.4951e-01, 9.5027e-01, 3.0336e-01, 1.7009e-01,\n",
      "        3.0852e+00, 1.6454e+00, 5.1855e-01, 6.7889e-01, 3.3588e+00, 6.6151e-01,\n",
      "        1.7645e+00, 8.3768e-01, 1.6668e+00, 9.8879e-01, 5.1794e-01, 5.8052e-01,\n",
      "        3.6657e-01, 1.8429e+03, 1.5078e+03, 4.1969e+00, 3.3186e-01, 3.4361e+00,\n",
      "        4.8525e+00, 1.9795e+00, 1.0770e+01, 2.1939e+01, 1.0559e+00, 3.0433e+01,\n",
      "        2.6352e+00, 5.8040e-01, 1.8347e+01, 8.3498e-01, 6.8599e-01, 2.3282e+00,\n",
      "        1.0113e+02, 4.1272e-01, 1.0238e+00, 2.6440e+00], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df = result\n",
    "# df['RGNTI_L1'] = df['label'].apply(literal_eval)\n",
    "\n",
    "# Flatten the 'keys' column\n",
    "all_labels = [label for sublist in df['RGNTI_L1'] for label in sublist]\n",
    "\n",
    "# Get unique classes\n",
    "unique_classes = np.unique(all_labels)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=unique_classes,\n",
    "    y=all_labels\n",
    ")\n",
    "\n",
    "# Create a dictionary mapping from class to weight\n",
    "class_weights_dict = dict(zip(unique_classes, class_weights))\n",
    "\n",
    "print(\"Class weights:\", class_weights_dict)\n",
    "print(class_weights)\n",
    "class_weights = torch.tensor(list(class_weights_dict.values()))\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_trainer(class_weights):\n",
    "    \n",
    "    class _WeightedBCELossTrainer(Trainer):\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            # self.loss_fct = torch.nn.BCEWithLogitsLoss(weight=torch.tensor(class_weights, device='cuda', dtype=torch.float))\n",
    "            self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            # forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get(\"logits\")\n",
    "            labels = labels.float() \n",
    "            # compute custom loss (suppose one has 3 labels with different weights)\n",
    "            # loss_fct = torch.nn.CrossEntropyLoss(weight=torch.tensor([0.5, 1.5], device=labels.device, dtype=logits.dtype))\n",
    "            loss = self.loss_fct(logits, labels)\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    return _WeightedBCELossTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 514795\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 84453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at miemBertProject/miem-scibert-linguistic and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 182,830 || all params: 178,071,644 || trainable%: 0.1027\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_lora_model(\n",
    "    embedding_model_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "# rank=lora_rank,\n",
    "#     alpha=lora_alpha,\n",
    "#     lora_dropout=lora_dropout,\n",
    "#     bias='none'\n",
    "# )\n",
    "\n",
    "# if args.set_pad_id: \n",
    "    # model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# move model to GPU device\n",
    "if model.device.type != 'cuda':\n",
    "    model=model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training function\n",
    "\"\"\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_path,\n",
    "    learning_rate=lr,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio= 0.1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    logging_steps=5000,\n",
    "    max_grad_norm= 0.3,\n",
    ")\n",
    "\n",
    "\n",
    "weighted_trainer = get_weighted_trainer(list(class_weights_dict.values()))\n",
    "\n",
    "trainer = weighted_trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.add_callback(CustomCallback(trainer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5c843ce04940ae9d250bdc1daf65a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5001, 'grad_norm': 0.13222931325435638, 'learning_rate': 6.215813028344107e-06, 'epoch': 0.31}\n",
      "{'loss': 0.1537, 'grad_norm': 0.033327579498291016, 'learning_rate': 9.981999376249983e-06, 'epoch': 0.62}\n",
      "{'loss': 0.1032, 'grad_norm': 0.027253005653619766, 'learning_rate': 9.773936894297323e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05fb2f77a3d447b99a2a922caa4728c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (514795, 46)\n",
      "{'train_loss': 0.09452324360609055, 'train_accuracy': 0.0005069979312153382, 'train_f1': 0.0011516760596548845, 'train_f1_macro': 0.0001977681730803016, 'train_f1_weighted': 0.001146305407391708, 'train_runtime': 2254.7027, 'train_samples_per_second': 228.321, 'train_steps_per_second': 7.135, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d9ccaf323b4e108c4a572caa3d4d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (84453, 46)\n",
      "{'eval_loss': 0.1275978982448578, 'eval_accuracy': 0.0005446816572531467, 'eval_f1': 0.0013094931286437691, 'eval_f1_macro': 0.0002539858632549303, 'eval_f1_weighted': 0.0013031400674927175, 'eval_runtime': 373.4936, 'eval_samples_per_second': 226.116, 'eval_steps_per_second': 7.068, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0953, 'grad_norm': 0.026362020522356033, 'learning_rate': 9.342226306376689e-06, 'epoch': 1.24}\n",
      "{'loss': 0.0904, 'grad_norm': 0.02458866313099861, 'learning_rate': 8.707204390479127e-06, 'epoch': 1.55}\n",
      "{'loss': 0.0865, 'grad_norm': 0.021311307325959206, 'learning_rate': 7.89819541128146e-06, 'epoch': 1.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b855938558a44d4b82b7c0fe32ccf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (514795, 46)\n",
      "{'train_loss': 0.0800972729921341, 'train_accuracy': 0.08401985256267058, 'train_f1': 0.1477398112628172, 'train_f1_macro': 0.02499738004377408, 'train_f1_weighted': 0.11126139330932752, 'train_runtime': 2237.4184, 'train_samples_per_second': 230.084, 'train_steps_per_second': 7.19, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13c5226ca2f49059e7e1ec67785c317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (84453, 46)\n",
      "{'eval_loss': 0.10971024632453918, 'eval_accuracy': 0.07590020484766676, 'eval_f1': 0.1281696813930697, 'eval_f1_macro': 0.02132969714070727, 'eval_f1_weighted': 0.09667334720638457, 'eval_runtime': 366.1311, 'eval_samples_per_second': 230.663, 'eval_steps_per_second': 7.211, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0835, 'grad_norm': 0.024259725585579872, 'learning_rate': 6.953735531960473e-06, 'epoch': 2.18}\n",
      "{'loss': 0.0812, 'grad_norm': 0.025461765006184578, 'learning_rate': 5.917555712021059e-06, 'epoch': 2.49}\n",
      "{'loss': 0.0793, 'grad_norm': 0.027708139270544052, 'learning_rate': 4.83838341546949e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f0cf1908ed4c40af200735bd8914a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (514795, 46)\n",
      "{'train_loss': 0.073717400431633, 'train_accuracy': 0.11893860662982352, 'train_f1': 0.20426966610474426, 'train_f1_macro': 0.0374985526451056, 'train_f1_weighted': 0.14797684721116974, 'train_runtime': 2235.3136, 'train_samples_per_second': 230.301, 'train_steps_per_second': 7.197, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97784b346acf4a7ebf6419243e38958a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (84453, 46)\n",
      "{'eval_loss': 0.10182597488164902, 'eval_accuracy': 0.1009555610813115, 'eval_f1': 0.17019310493237214, 'eval_f1_macro': 0.030234829015452255, 'eval_f1_weighted': 0.12385600054330675, 'eval_runtime': 366.0317, 'eval_samples_per_second': 230.726, 'eval_steps_per_second': 7.212, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0779, 'grad_norm': 0.024034636095166206, 'learning_rate': 3.7667837350975524e-06, 'epoch': 3.11}\n",
      "{'loss': 0.0769, 'grad_norm': 0.027668477967381477, 'learning_rate': 2.7529669454339756e-06, 'epoch': 3.42}\n",
      "{'loss': 0.0763, 'grad_norm': 0.025287026539444923, 'learning_rate': 1.844435878238826e-06, 'epoch': 3.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad2d05cd51a4b0bbe7e8981f6753e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (514795, 46)\n",
      "{'train_loss': 0.07149530202150345, 'train_accuracy': 0.1325576200235045, 'train_f1': 0.22675597701454245, 'train_f1_macro': 0.045804461926193946, 'train_f1_weighted': 0.16510007205464594, 'train_runtime': 2279.8729, 'train_samples_per_second': 225.8, 'train_steps_per_second': 7.057, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a18640744f4453964c8b2d1ce657f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (84453, 46)\n",
      "{'eval_loss': 0.09906462579965591, 'eval_accuracy': 0.1108308763454229, 'eval_f1': 0.18715787100249276, 'eval_f1_macro': 0.036200677077417025, 'eval_f1_weighted': 0.13627970435301434, 'eval_runtime': 372.6552, 'eval_samples_per_second': 226.625, 'eval_steps_per_second': 7.084, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\PowerfullProject\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0759, 'grad_norm': 0.02331838198006153, 'learning_rate': 1.0837601564200822e-06, 'epoch': 4.04}\n",
      "{'loss': 0.0755, 'grad_norm': 0.022498829290270805, 'learning_rate': 5.065815756216214e-07, 'epoch': 4.35}\n",
      "{'loss': 0.0754, 'grad_norm': 0.021427739411592484, 'learning_rate': 1.39893122364011e-07, 'epoch': 4.66}\n",
      "{'loss': 0.0755, 'grad_norm': 0.02103545144200325, 'learning_rate': 1.0222747765559204e-09, 'epoch': 4.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d04f97ef6be4dcab96850fd36e0ef4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (514795, 46)\n",
      "{'train_loss': 0.07117845863103867, 'train_accuracy': 0.13442826756281626, 'train_f1': 0.22988089484174798, 'train_f1_macro': 0.04721275371259912, 'train_f1_weighted': 0.16770386538391518, 'train_runtime': 2280.5209, 'train_samples_per_second': 225.736, 'train_steps_per_second': 7.055, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c162ad8cd9434505a22863ecfc1e5d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (84453, 46)\n",
      "{'eval_loss': 0.09867217391729355, 'eval_accuracy': 0.11205048962144624, 'eval_f1': 0.18938375227504423, 'eval_f1_macro': 0.03723334856105703, 'eval_f1_weighted': 0.13815616834101277, 'eval_runtime': 373.1646, 'eval_samples_per_second': 226.316, 'eval_steps_per_second': 7.075, 'epoch': 5.0}\n",
      "{'train_runtime': 26471.8524, 'train_samples_per_second': 97.234, 'train_steps_per_second': 3.039, 'train_loss': 0.11272009233525, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80440, training_loss=0.11272009233525, metrics={'train_runtime': 26471.8524, 'train_samples_per_second': 97.234, 'train_steps_per_second': 3.039, 'train_loss': 0.11272009233525, 'epoch': 5.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
